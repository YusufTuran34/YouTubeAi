# YouTube AI Bot

This project includes shell scripts for generating and uploading YouTube videos automatically. The title and description generation scripts now support using OpenAI for smarter, SEO friendly content.

## Configuration
Shared settings live in `sh_scripts/configs/base.conf`. Example keys:

```bash
VIDEO_FILE="sample.mp4"        # Input video
OPENAI_API_KEY="sk-..."        # Your OpenAI token
OPENAI_MODEL="gpt-3.5-turbo"   # Optional
KEYWORDS="lofi, study music"
```

Per-channel credentials are kept in `sh_scripts/channels.env` as a JSON array.
Add a new object for each channel. Credentials are grouped by service:

```bash
CHANNEL_CONFIGS='[
  {
    "name": "default",
    "youtube": {
      "CLIENT_ID": "xxx",
      "CLIENT_SECRET": "yyy",
      "REFRESH_TOKEN": "zzz",
      "STREAM_KEY": "stream"
    },
    "twitter": {
      "API_KEY": "",
      "API_SECRET": "",
      "ACCESS_TOKEN": "",
      "ACCESS_SECRET": ""
    }
  },
  {
    "name": "alt",
    "youtube": {
      "CLIENT_ID": "id2",
      "CLIENT_SECRET": "secret2",
      "REFRESH_TOKEN": "token2",
      "STREAM_KEY": "stream2"
    },
    "twitter": {
      "API_KEY": "",
      "API_SECRET": "",
      "ACCESS_TOKEN": "",
      "ACCESS_SECRET": ""
    }
  }
]'
```
Source `channels.env` and set `CHANNEL` to pick a config before running scripts:
You can override the file path with the `CHANNEL_ENV_FILE` environment variable.

```bash
sh sh_scripts/generate_title.sh
sh sh_scripts/generate_description.sh
```

If `OPENAI_API_KEY` is not set or the API call fails, the scripts fall back to basic templates.
Use helper scripts for common tasks:

- `sh sh_scripts/run_generation_pipeline.sh` - generate video, description, thumbnail and title sequentially.
- `sh sh_scripts/run_pipeline_and_upload.sh <hours> [options]` - run the pipeline and optionally upload and tweet.
- `sh sh_scripts/run_pipeline_and_stream.sh <hours> [options]` - run the pipeline then stream the result and optionally tweet.


When scheduling jobs via the web UI you can also specify optional parameters that
will be passed to the script. For example a job with `scriptPath` set to
`sh_scripts/run_pipeline_and_stream.sh` and `scriptParams` of `12 --post-twitter --tag lofi` will start a
12 hour stream and post to Twitter using the `lofi` tag.

`src/main/resources/init.sql` includes sample jobs for daily streaming, uploading,
and a standalone tweet job that calls `post_to_twitter.sh --tag lofi`. Each job
specifies a `channel` value so the correct credentials are loaded from
`channels.env`.

## Twitter Posting
Twitter credentials are read from the selected channel entry in `channels.env` or a channel specific config file:
```
TWITTER_API_KEY="..."
TWITTER_API_SECRET="..."
TWITTER_ACCESS_TOKEN="..."
TWITTER_ACCESS_SECRET="..."
```
If these variables are empty the `post_to_twitter.sh` script logs a message and exits without posting.
After uploading a video or starting a stream you can notify followers with:
```
sh sh_scripts/post_to_twitter.sh
```
The tweet text will be generated by ChatGPT unless you pass `--message`.
You can also override the video style with `--tag` or provide a URL with `--url`.
To automate tweeting after a job finishes pass the `--post-twitter` flag when running the pipeline scripts.
Example of tweeting by itself:
```bash
sh sh_scripts/post_to_twitter.sh --tag lofi
```
